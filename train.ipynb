{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import time\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "from model import ConvStackModel\n",
    "from dataset import MNISTDataset\n",
    "\n",
    "# sci_mode=True is the default which will print values such as 9.8e-01 instead of 0.98.\n",
    "torch.set_printoptions(precision=3, sci_mode=False)\n",
    "# manually specify how floats should be printed. Notably, this override uses more spacing\n",
    "# which I feel makes array easier to read.\n",
    "np.set_printoptions(formatter={'float': lambda val: f\" {val:.3f} \"}, linewidth=100)\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setup the dataloader, model, loss function & optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_dataset_train = MNISTDataset(split=\"train\")\n",
    "batch_size = 64\n",
    "mnist_data_loader_train = torch.utils.data.DataLoader(dataset=mnist_dataset_train, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "model = ConvStackModel()\n",
    "\n",
    "bce_loss_fn = torch.nn.BCELoss(reduction='sum')\n",
    "adam_optimizer = torch.optim.Adam(params=model.parameters(), lr=3e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pull an example element & example batch from the dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_image, single_label = mnist_dataset_train[672]\n",
    "\n",
    "# A DataLoader is a Python Iterable (not to be confused with an Iterator). As the name suggests, an Iterable\n",
    "# is able to be iterated over. The iteration is supported or done by a seperate object called an Iterator. Generally,\n",
    "# an Iterable implements the __iter__ method which creates & returns an Iterator object.\n",
    "mnist_data_loader_train_iterator = iter(mnist_data_loader_train)\n",
    "batch_of_images, batch_of_labels = next(mnist_data_loader_train_iterator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training-step using one image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model(single_image)\n",
    "\n",
    "# The target, or ideal prediction, would have a zero for each irrelevant digit, and a one \n",
    "# for the relevant digit (i.e. the label).\n",
    "target = torch.zeros_like(predictions)\n",
    "target[single_label.item()] = 1.0\n",
    "\n",
    "loss_score = bce_loss_fn(input=predictions, target=target)\n",
    "\n",
    "print(f\"The model predicted: \\n{predictions.data.numpy()}. \\nThe target is: \\n{target.data.numpy()}.\")\n",
    "print(f\"Loss score: {loss_score:.3f}.\")\n",
    "\n",
    "loss_score.backward()\n",
    "adam_optimizer.step()\n",
    "adam_optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training-step using a batch of images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_num_random_batch_entries(predictions: torch.Tensor, target: torch.Tensor, num_entries_to_print: int = 3):\n",
    "    # The final batch in an epoch may have a batch-size smaller than the rest.\n",
    "    actual_batch_size = predictions.shape[0]\n",
    "    random_indices_to_print = sorted(random.sample(range(0, actual_batch_size), k=num_entries_to_print))\n",
    "    \n",
    "    for random_idx in random_indices_to_print:\n",
    "    \n",
    "        print(f\"Batch-entry: {random_idx}.\")\n",
    "        print(f\"predictions: \\n{predictions[random_idx].data.numpy()}\")\n",
    "        print(f\"target: \\n{target[random_idx].data.numpy()}\")\n",
    "        print()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model(batch_of_images)\n",
    "\n",
    "# Again, the target should have 0's for each irrelevant digit and 1 for the relevant digit, for each entry (or image) in\n",
    "# the batch.\n",
    "batch_indices = torch.tensor(range(0, len(batch_of_labels)))\n",
    "target = torch.zeros_like(predictions)\n",
    "target[batch_indices, batch_of_labels.to(torch.int64)] = 1.0\n",
    "\n",
    "loss_score = bce_loss_fn(input=predictions, target=target)\n",
    "\n",
    "# Find the probability each entry is correct.\n",
    "# We choose the predicted probability (i.e. the values in predictions) is the probability that each entry is True \n",
    "# i.e. the input-image is that given digit. The probability the entry is False can be inferred by taking 1 - p.\n",
    "# For entries where target is 1, (1-target) is 0, minus the predicted probability then an absolute value, the result \n",
    "# is the predicted probability for class=1 (i.e. True).\n",
    "# For entries where target is 0, (1-target) is 1, 1-minus the predicted probability gives us the predicted probability for \n",
    "# class=0 (i.e. False).\n",
    "probability_is_correct = ((1 - target) - predictions).abs()\n",
    "\n",
    "# The inferred joint-probability predicted for every correct class in the batch. Change the data-type from float32 to float64\n",
    "# to reduce the likelihood of underflowing to 0.\n",
    "joint_probability = probability_is_correct.to(torch.float64).prod()\n",
    "# We can also recover this joint-probability from the loss-score, since we know the loss = -log(joint_probability).\n",
    "joint_probability_from_loss = math.exp(-loss_score)\n",
    "# The joint-probability is the product of all probabilities, so we invert that step to get the per batch-element \n",
    "# average probability.\n",
    "per_batch_element_average_probability = joint_probability_from_loss ** (1 / predictions.numel())\n",
    "\n",
    "print_num_random_batch_entries(predictions, target)\n",
    "\n",
    "# Note: The smallest float Python can represent is roughly 1e-325. Beyond that, the value becomes 0. \n",
    "# This is roughly equal to e^-745. Accordingly, any loss values above 745 result in an inferred \n",
    "# probability that underflows to 0.\n",
    "# Similarly, the smallest float the torch64 datatype can represent is roughly 1e-308 or about e^-710.\n",
    "print(f\"Joint probability: {joint_probability:.2e}. Joint probability inferred from loss-score: {joint_probability_from_loss:.2e}.\")\n",
    "print(f\"The per batch-element average probability is: {per_batch_element_average_probability:.3f}.\")\n",
    "print(f\"Loss score: {loss_score:.3f}\")\n",
    "\n",
    "loss_score.backward()\n",
    "adam_optimizer.step()\n",
    "adam_optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train for num_epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 20\n",
    "num_batches_per_epoch = math.ceil(len(mnist_dataset_train) / batch_size)\n",
    "num_batches_to_print_per_epoch = 2\n",
    "\n",
    "for epoch_idx in range(num_epochs):\n",
    "    print(f\"\\nBeginning epoch: {epoch_idx + 1}.\")\n",
    "    \n",
    "    for batch_idx, (batch_of_images, batch_of_labels) in enumerate(mnist_data_loader_train):\n",
    "        \n",
    "        predictions = model(batch_of_images)\n",
    "        \n",
    "        batch_indices = torch.tensor(range(0, len(batch_of_labels)))\n",
    "        target = torch.zeros_like(predictions)\n",
    "        target[batch_indices, batch_of_labels.to(torch.int64)] = 1.0\n",
    "        \n",
    "        loss_score = bce_loss_fn(input=predictions, target=target)\n",
    "        joint_probability_from_loss = math.exp(-loss_score)\n",
    "\n",
    "        # Note: the last batch may contain less than batch-size elements.\n",
    "        per_batch_element_average_probability = joint_probability_from_loss ** (1 / predictions.numel())\n",
    "\n",
    "        # Only print the first few batches of results for each epoch.\n",
    "        if batch_idx < num_batches_to_print_per_epoch:\n",
    "            print(\n",
    "                f\"Batch: {batch_idx + 1}. \"\n",
    "                f\"Joint probability inferred from loss-score: {joint_probability_from_loss:.2e}. \"\n",
    "                f\"Per batch-element average probability is: {per_batch_element_average_probability:.3f} \"\n",
    "                f\"Loss score: {loss_score:.3f}\"\n",
    "            )\n",
    "            \n",
    "            # Add a sleep to be able to watch in real-time. Otherwise, the process is too quick.\n",
    "            time.sleep(2)\n",
    "        \n",
    "        elif batch_idx == num_batches_to_print_per_epoch:\n",
    "            print(\n",
    "                f\"Accelerating through the remaining {num_batches_per_epoch - num_batches_to_print_per_epoch:,} \"\n",
    "                f\"batches in this epoch without printing updates...\"\n",
    "            )\n",
    "        \n",
    "\n",
    "        loss_score.backward()\n",
    "        adam_optimizer.step()\n",
    "        adam_optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save the model's learned parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_weights = model.state_dict()\n",
    "# state_dict() is a Python dictionary that maps a string-name (e.g. conv_stack.0.weight, conv_stack_1.bias, etc.)\n",
    "# to the relevant parameter-tensor.\n",
    "print(f\"Entries in model.state_dict():\")\n",
    "for idx, (k, v) in enumerate(model_weights.items()):\n",
    "    if idx >= 5:\n",
    "        break\n",
    "\n",
    "    print(f\"key: {k}\")\n",
    "    print(f\"value.shape: {v.shape}\")\n",
    "print(\"...\\n\")\n",
    "\n",
    "model_weights_filename = \"model_weights.pt\"\n",
    "print(f\"Saving model parameters to {model_weights_filename}\")\n",
    "torch.save(obj=model.state_dict(), f=model_weights_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### View some sample outputs of the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model(batch_of_images)\n",
    "\n",
    "batch_indices = torch.tensor(range(0, len(batch_of_labels)))\n",
    "target = torch.zeros_like(predictions)\n",
    "target[batch_indices, batch_of_labels.to(torch.int64)] = 1.0\n",
    "\n",
    "print_num_random_batch_entries(predictions, target, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
