{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import time\n",
    "\n",
    "import torch\n",
    "\n",
    "from model import ConvStackModel\n",
    "from dataset import MNISTDataset\n",
    "\n",
    "# sci_mode=True is the default which will print values such as 9.8e-01 instead of 0.98.\n",
    "torch.set_printoptions(precision=3, sci_mode=False)\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setup the dataloader, model, loss function & optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_dataset_train = MNISTDataset(split=\"train\")\n",
    "batch_size = 32\n",
    "mnist_data_loader_train = torch.utils.data.DataLoader(dataset=mnist_dataset_train, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "model = ConvStackModel()\n",
    "\n",
    "bce_loss_fn = torch.nn.BCELoss(reduction='sum')\n",
    "adam_optimizer = torch.optim.Adam(params=model.parameters(), lr=4e-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pull an example element & example batch from the dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A DataLoader is a Python Iterable (not to be confused with an Iterator). As the name suggests, an Iterable\n",
    "# is able to be iterated over. The iteration is supported or done by a seperate object called an Iterator. Generally,\n",
    "# an Iterable implements the __iter__ method which creates & returns an Iterator object.\n",
    "mnist_data_loader_train_iterator = iter(mnist_data_loader_train)\n",
    "\n",
    "batch_of_images, batch_of_labels = next(mnist_data_loader_train_iterator)\n",
    "single_image, single_label = mnist_dataset_train[672]\n",
    "# Add a batch-dimension with a single entry i.e. of size 1.\n",
    "single_image = single_image.unsqueeze(dim=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training-step using one image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model predicted a probability of 0.00 for the correct clas.\n",
      "Loss score: 8.414.\n"
     ]
    }
   ],
   "source": [
    "predictions = model(single_image)\n",
    "probability_of_correct_class = predictions[:, single_label.item()].squeeze()\n",
    "loss_score = bce_loss_fn(input=probability_of_correct_class, target=torch.tensor(1.0))\n",
    "\n",
    "print(f\"Model predicted a probability of {probability_of_correct_class:.2f} for the correct clas.\")\n",
    "print(f\"Loss score: {loss_score:.3f}.\")\n",
    "\n",
    "loss_score.backward()\n",
    "adam_optimizer.step()\n",
    "adam_optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training-step using a batch of images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Joint probability: 6.69e-35. Joint probability inferred from loss-score: 6.69e-35.\n",
      "The per batch-element average probability is: 0.086.\n",
      "Loss score: 78.691\n"
     ]
    }
   ],
   "source": [
    "predictions = model(batch_of_images)\n",
    "\n",
    "correct_class_indices = batch_of_labels.unsqueeze(dim=1).to(torch.int64)\n",
    "probability_of_correct_classes = predictions.gather(dim=1, index=correct_class_indices).squeeze()\n",
    "\n",
    "loss_score = bce_loss_fn(input=probability_of_correct_classes, target=torch.ones(size=(batch_size,)))\n",
    "\n",
    "# The inferred joint-probability predicted for every correct class in the batch. Change the data-type from float32 to float64\n",
    "# to reduce the likelihood of underflowing to 0.\n",
    "joint_probability = probability_of_correct_classes.to(torch.float64).prod()\n",
    "# We can also recover this joint-probability from the loss-score, since we know the loss is computed as -log(joint_probability).\n",
    "joint_probability_from_loss = math.exp(-loss_score)\n",
    "# The joint-probability is the product of all probabilities, so we invert that step to get the per batch-element \n",
    "# average probability.\n",
    "per_batch_element_average_probability = joint_probability_from_loss ** (1/batch_size)\n",
    "\n",
    "print(f\"Joint probability: {joint_probability:.2e}. Joint probability inferred from loss-score: {joint_probability_from_loss:.2e}.\")\n",
    "print(f\"The per batch-element average probability is: {per_batch_element_average_probability:.3f}.\")\n",
    "print(f\"Loss score: {loss_score:.3f}\")\n",
    "\n",
    "loss_score.backward()\n",
    "adam_optimizer.step()\n",
    "adam_optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train for num_epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Beginning epoch: 1.\n",
      "Batch: 1. Joint probability inferred from loss-score: 3.04e-43. Per batch-element average probability is: 0.047 Loss score: 97.899\n",
      "Batch: 2. Joint probability inferred from loss-score: 9.05e-53. Per batch-element average probability is: 0.024 Loss score: 119.835\n",
      "Batch: 3. Joint probability inferred from loss-score: 4.55e-38. Per batch-element average probability is: 0.068 Loss score: 85.984\n",
      "Batch: 4. Joint probability inferred from loss-score: 9.98e-56. Per batch-element average probability is: 0.019 Loss score: 126.644\n",
      "Batch: 5. Joint probability inferred from loss-score: 2.54e-34. Per batch-element average probability is: 0.089 Loss score: 77.355\n",
      "Batch: 6. Joint probability inferred from loss-score: 2.08e-23. Per batch-element average probability is: 0.196 Loss score: 52.225\n",
      "Batch: 7. Joint probability inferred from loss-score: 4.61e-17. Per batch-element average probability is: 0.309 Loss score: 37.615\n",
      "Batch: 8. Joint probability inferred from loss-score: 4.36e-25. Per batch-element average probability is: 0.173 Loss score: 56.093\n",
      "Batch: 9. Joint probability inferred from loss-score: 2.24e-29. Per batch-element average probability is: 0.127 Loss score: 65.969\n",
      "Batch: 10. Joint probability inferred from loss-score: 1.03e-32. Per batch-element average probability is: 0.100 Loss score: 73.651\n",
      "Accelerating through the remaining 1,865 batches in this epoch without printing updates...\n",
      "\n",
      "Beginning epoch: 2.\n",
      "Batch: 1. Joint probability inferred from loss-score: 9.90e-01. Per batch-element average probability is: 1.000 Loss score: 0.010\n",
      "Batch: 2. Joint probability inferred from loss-score: 9.85e-01. Per batch-element average probability is: 1.000 Loss score: 0.015\n",
      "Batch: 3. Joint probability inferred from loss-score: 9.99e-01. Per batch-element average probability is: 1.000 Loss score: 0.001\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[101], line 31\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[1;32m     24\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBatch: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbatch_idx\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     25\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mJoint probability inferred from loss-score: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mjoint_probability_from_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2e\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     26\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPer batch-element average probability is: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mper_batch_element_average_probability\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     27\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoss score: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloss_score\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     28\u001b[0m     )\n\u001b[1;32m     30\u001b[0m     \u001b[38;5;66;03m# Add a sleep to be able to watch in real-time. Otherwise, the process is too quick.\u001b[39;00m\n\u001b[0;32m---> 31\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m batch_idx \u001b[38;5;241m==\u001b[39m num_batches_to_print_per_epoch:\n\u001b[1;32m     34\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[1;32m     35\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAccelerating through the remaining \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_batches_per_epoch\u001b[38;5;250m \u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;250m \u001b[39mnum_batches_to_print_per_epoch\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m,\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     36\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatches in this epoch without printing updates...\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     37\u001b[0m     )\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "num_epochs = 3\n",
    "num_batches_per_epoch = math.ceil(len(mnist_dataset_train) / batch_size)\n",
    "num_batches_to_print_per_epoch = 10\n",
    "\n",
    "for epoch_idx in range(num_epochs):\n",
    "    print(f\"\\nBeginning epoch: {epoch_idx + 1}.\")\n",
    "    \n",
    "    for batch_idx, (batch_of_images, batch_of_labels) in enumerate(mnist_data_loader_train):\n",
    "        \n",
    "        predictions = model(batch_of_images)\n",
    "        \n",
    "        correct_class_indices = batch_of_labels.unsqueeze(dim=1).to(torch.int64)\n",
    "        probability_of_correct_classes = predictions.gather(dim=1, index=correct_class_indices).squeeze()\n",
    "        \n",
    "        loss_score = bce_loss_fn(input=probability_of_correct_classes, target=torch.ones_like(probability_of_correct_classes))\n",
    "        joint_probability_from_loss = math.exp(-loss_score)\n",
    "\n",
    "        # Note: the last batch may contain less than batch-size elements.\n",
    "        per_batch_element_average_probability = joint_probability_from_loss ** (1 / len(batch_of_labels))\n",
    "\n",
    "        # Only print the first few batches of results for each epoch.\n",
    "        if batch_idx < num_batches_to_print_per_epoch:\n",
    "            print(\n",
    "                f\"Batch: {batch_idx + 1}. \"\n",
    "                f\"Joint probability inferred from loss-score: {joint_probability_from_loss:.2e}. \"\n",
    "                f\"Per batch-element average probability is: {per_batch_element_average_probability:.3f} \"\n",
    "                f\"Loss score: {loss_score:.3f}\"\n",
    "            )\n",
    "            \n",
    "            # Add a sleep to be able to watch in real-time. Otherwise, the process is too quick.\n",
    "            time.sleep(2)\n",
    "        \n",
    "        elif batch_idx == num_batches_to_print_per_epoch:\n",
    "            print(\n",
    "                f\"Accelerating through the remaining {num_batches_per_epoch - num_batches_to_print_per_epoch:,} \"\n",
    "                f\"batches in this epoch without printing updates...\"\n",
    "            )\n",
    "        \n",
    "\n",
    "        loss_score.backward()\n",
    "        adam_optimizer.step()\n",
    "        adam_optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
